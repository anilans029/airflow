{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7e9a3c",
   "metadata": {},
   "source": [
    "#  üöÄ Airflow 2.3 Installation Guide (WSL + MySQL + Celery Executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6238863",
   "metadata": {},
   "source": [
    "\n",
    "This guide explains how to set up **Apache Airflow 2.3** inside **WSL (Ubuntu)** using **MySQL** as the metadata DB and **CeleryExecutor** for distributed task execution.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Prerequisites\n",
    "\n",
    "* Windows 10/11 with **WSL2** enabled\n",
    "* Installed **Ubuntu (20.04 or 22.04)** from Microsoft Store\n",
    "* Python **3.9** (Airflow 2.3 doesn‚Äôt support Python 3.12)\n",
    "* MySQL server installed (inside WSL)\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Update System & Install Dependencies\n",
    "\n",
    "```bash\n",
    "sudo apt update && sudo apt upgrade -y\n",
    "sudo apt install -y python3.9 python3.9-venv python3.9-distutils \\\n",
    "    mysql-server libmysqlclient-dev gcc build-essential \\\n",
    "    libssl-dev libffi-dev python3-dev\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Create Airflow Project Directory\n",
    "\n",
    "```bash\n",
    "mkdir ~/airflow_course && cd ~/airflow_course\n",
    "python3.9 -m venv venv\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Install Apache Airflow 2.3\n",
    "\n",
    "Set environment variables:\n",
    "\n",
    "```bash\n",
    "export AIRFLOW_HOME=~/airflow_course/airflow\n",
    "```\n",
    "\n",
    "Install Airflow with MySQL + Celery extras:\n",
    "\n",
    "```bash\n",
    "pip install \"apache-airflow[celery,mysql]==2.3.0\" --constraint \\\n",
    "\"https://raw.githubusercontent.com/apache/airflow/constraints-2.3.0/constraints-3.9.txt\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Configure MySQL for Airflow\n",
    "\n",
    "Start MySQL service:\n",
    "\n",
    "```bash\n",
    "sudo service mysql start\n",
    "```\n",
    "\n",
    "Login to MySQL:\n",
    "\n",
    "```bash\n",
    "sudo mysql -u root\n",
    "```\n",
    "\n",
    "Inside MySQL shell:\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE airflow_db;\n",
    "CREATE USER 'airflow_user'@'localhost' IDENTIFIED BY 'airflow_pass';\n",
    "GRANT ALL PRIVILEGES ON airflow_db.* TO 'airflow_user'@'localhost';\n",
    "FLUSH PRIVILEGES;\n",
    "EXIT;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Initialize Airflow Config\n",
    "\n",
    "Generate default config:\n",
    "\n",
    "```bash\n",
    "airflow db init\n",
    "```\n",
    "\n",
    "This will create `~/airflow_course/airflow/airflow.cfg`.\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Update airflow\\.cfg\n",
    "\n",
    "Edit:\n",
    "\n",
    "```bash\n",
    "nano ~/airflow_course/airflow/airflow.cfg\n",
    "```\n",
    "\n",
    "Change:\n",
    "\n",
    "### Executor:\n",
    "\n",
    "```ini\n",
    "executor = CeleryExecutor\n",
    "```\n",
    "\n",
    "### Database:\n",
    "\n",
    "```ini\n",
    "sql_alchemy_conn = mysql+mysqldb://airflow_user:airflow_pass@localhost/airflow_db\n",
    "```\n",
    "\n",
    "### Celery:\n",
    "\n",
    "```ini\n",
    "[celery]\n",
    "broker_url = redis://localhost:6379/0\n",
    "result_backend = db+mysql://airflow_user:airflow_pass@localhost/airflow_db\n",
    "```\n",
    "\n",
    "*(Here we use Redis as the Celery broker. Install it with `sudo apt install redis-server`.)*\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ Initialize DB with MySQL\n",
    "\n",
    "```bash\n",
    "airflow db reset -y   # if re-running\n",
    "airflow db init\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ Create Admin User\n",
    "\n",
    "```bash\n",
    "airflow users create \\\n",
    "    --username admin \\\n",
    "    --firstname First \\\n",
    "    --lastname Last \\\n",
    "    --role Admin \\\n",
    "    --email admin@example.com \\\n",
    "    --password admin\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîü Start Airflow Components\n",
    "\n",
    "Open 3 terminals (all inside `~/airflow_course` and `source venv/bin/activate`):\n",
    "\n",
    "**Terminal 1 ‚Äì Scheduler**\n",
    "\n",
    "```bash\n",
    "airflow scheduler\n",
    "```\n",
    "\n",
    "**Terminal 2 ‚Äì Webserver**\n",
    "\n",
    "```bash\n",
    "airflow webserver -p 8080 --hostname 0.0.0.0\n",
    "```\n",
    "\n",
    "**Terminal 3 ‚Äì Celery Worker**\n",
    "\n",
    "```bash\n",
    "airflow celery worker\n",
    "```\n",
    "\n",
    "(Optional) **Celery Flower (monitoring UI):**\n",
    "\n",
    "```bash\n",
    "airflow celery flower\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ Access Airflow UI\n",
    "\n",
    "Open in Windows browser:\n",
    "üëâ [http://localhost:8080](http://localhost:8080)\n",
    "Login with:\n",
    "\n",
    "* **Username**: admin\n",
    "* **Password**: admin\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ Verify Installation\n",
    "\n",
    "1. Enable example DAGs in `airflow.cfg`:\n",
    "\n",
    "   ```ini\n",
    "   load_examples = True\n",
    "   ```\n",
    "2. Restart scheduler & webserver.\n",
    "3. Trigger a sample DAG in the UI and check if a worker executes it.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Done! You now have **Airflow 2.3 running with MySQL + CeleryExecutor** inside WSL.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to also make you a **visual architecture diagram** (Airflow Scheduler + Webserver + Worker + MySQL + Redis) so you can keep it in your documentation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c5e38",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25fc2623",
   "metadata": {},
   "source": [
    "# Errors Faced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569e70f",
   "metadata": {},
   "source": [
    "I have compiled the following documentation for the errors you encountered during your Airflow installation. It's organized to help you quickly identify the issue, understand its cause, and apply the correct solution.\n",
    "\n",
    "## Airflow Installation & Configuration Errors\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. `ImportError: Module \"airflow.utils.net\" does not define a \"getfqdn\" attribute/class`\n",
    "\n",
    "**Description:** This error occurs when the Airflow scheduler or other components try to start but fail because a required function, `airflow.utils.net.getfqdn`, is missing.\n",
    "\n",
    "**Cause:** This is a compatibility issue with Airflow versions 2.4 and newer. The `airflow.utils.net.getfqdn` function was removed in favor of Python's standard `socket.getfqdn` function. Your `airflow.cfg` file is configured to use the deprecated function.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "1.  Open your `airflow.cfg` file.\n",
    "2.  In the `[core]` section, find the `hostname_callable` key.\n",
    "3.  Change its value from `airflow.utils.net.getfqdn` to `socket.getfqdn`.\n",
    "4.  Save the file and restart your Airflow components.\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. `sqlalchemy.exc.OperationalError: (MySQLdb.OperationalError) (1054, \"Unknown column 'task_instance.run_id'\")`\n",
    "\n",
    "**Description:** When you try to run the Airflow scheduler or other components, they fail with an error stating that the `run_id` column is not found in the `task_instance` table.\n",
    "\n",
    "**Cause:** This error indicates a schema mismatch. You have an updated version of the Airflow code (2.0+) that expects the database schema to be at a certain revision, but your database is on an older schema. The `run_id` column was added in a database migration that has not yet been applied.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "1.  Run the database migration command to update the schema to the correct version.\n",
    "    ```bash\n",
    "    airflow db upgrade\n",
    "    ```\n",
    "2.  Once the command finishes successfully, you can start the Airflow scheduler and webserver.\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. `sqlalchemy.exc.OperationalError: (MySQLdb.OperationalError) (1061, \"Duplicate key name 'idx_job_state_heartbeat'\")`\n",
    "\n",
    "**Description:** The `airflow db upgrade` command fails with a \"Duplicate key name\" error when attempting to add an index.\n",
    "\n",
    "**Cause:** This indicates a corrupted or incomplete database migration. A previous attempt to run `airflow db upgrade` was interrupted after it created the index but before it recorded the migration as complete. As a result, the index exists, but Airflow's internal versioning doesn't know about it, so it tries to create it again.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "1.  Connect to your MySQL database.\n",
    "    ```bash\n",
    "    mysql -u anil -p airflow_db\n",
    "    ```\n",
    "2.  Manually drop the duplicate index.\n",
    "    ```sql\n",
    "    ALTER TABLE job DROP INDEX idx_job_state_heartbeat;\n",
    "    ```\n",
    "3.  Exit MySQL and re-run the `airflow db upgrade` command.\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. `sqlalchemy.exc.OperationalError: (MySQLdb.OperationalError) (1060, \"Duplicate column name 'extra'\")`\n",
    "\n",
    "**Description:** The `airflow db upgrade` command fails with a \"Duplicate column name\" error when trying to add a new column to a table.\n",
    "\n",
    "**Cause:** Similar to the previous error, this is a sign of a partial database migration. The `extra` column was added to the `log` table, but the migration script was interrupted before completing.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "1.  Connect to your MySQL database.\n",
    "    ```bash\n",
    "    mysql -u anil -p airflow_db\n",
    "    ```\n",
    "2.  Manually drop the duplicate column.\n",
    "    ```sql\n",
    "    ALTER TABLE log DROP COLUMN extra;\n",
    "    ```\n",
    "3.  Exit MySQL and re-run the `airflow db upgrade` command.\n",
    "\n",
    "-----\n",
    "\n",
    "### General Recommendation: Re-initialization\n",
    "\n",
    "When faced with persistent or complex schema issues, the safest and most effective solution is to **start with a clean database**. This avoids any lingering inconsistencies and ensures that `airflow db init` can run smoothly.\n",
    "\n",
    "**How to re-initialize your Airflow database:**\n",
    "\n",
    "1.  **Drop and re-create the database**:\n",
    "    ```bash\n",
    "    mysql -u anil -p\n",
    "    DROP DATABASE airflow_db;\n",
    "    CREATE DATABASE airflow_db CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\n",
    "    GRANT ALL PRIVILEGES ON airflow_db.* TO 'anil'@'localhost';\n",
    "    FLUSH PRIVILEGES;\n",
    "    exit;\n",
    "    ```\n",
    "2.  **Initialize Airflow database**:\n",
    "    ```bash\n",
    "    airflow db init\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946aca3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
